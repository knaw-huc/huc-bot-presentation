<speak>
<express-as type="GoodNews">
	What if you took a group of software engineers with access to the world’s largest dataset on social economic development? And you add a group of specialists in language technology? And some semantic web experts, some image professionals, with a bunch of digital humanists thrown in for good measure? And you shake long and hard. What do you get? 

	A crazy mix of over fifty servers, a dozen operating systems, and more than five hundred pieces of homemade software in various states of maturity. That’s what you get. Millions of lines of code. A vibrant, nerdy, musical, loud, and generally fantastic mix of knowledge, enthusiasm and pride. A bunch of people aching to at least double that codebase… yearly. 

	You’d be crazy if you’d wish to do that in a responsible academic environment of contemplating intellectuals. Wouldn’t you?
	<break strength="medium"/><prosody volume="x-loud"><voice-transformation type="Custom" rate="fast" strength="100%">And yet we still did!</voice-transformation></prosody>

	<break strength="medium"/>Now we’re here and we wonder: where the heck do we go? There is only one way out. <break strength="weak"/><prosody volume="x-loud"><voice-transformation type="Custom" rate="fast" strength="100%">Full steam ahead and damn the torpedoes!</voice-transformation></prosody>
</express-as>
</speak>

<speak>
<express-as type="GoodNews">
	Engineers at the cluster have been applying software to the humanities and social sciences for more than fifteen years. They built tools for archives<break strength="weak"/> as well as research software. Technically we would say that the five hundred pieces of code making up the two groups are <break strength="weak"/>‘loosely coupled’. <break strength="weak"/>But after a couple of beers we would admit that they hardly talk to each other. <break strength="weak"/><prosody volume="x-loud"><voice-transformation type="Custom" rate="fast" strength="100%">The software, not the engineers.</voice-transformation></prosody>

	<break strength="medium"/>Our primary aim now is to figure out how to connect the most important codebases. To turn five hundred tools into lego-blocks that together serve users. We want to let researchers select data from the archives and run these through chains of connected language and image software.<break strength="weak"/> Extract information and enrich original sources. <break strength="weak"/>The results are then returned to scientists for further human analysis.<break strength="weak"/> In connected user-friendly platforms, as well as raw data, ready for processing in other tools, such as Gephi, SPSS, Q gis, or R.

	<break strength="medium"/>Building these connections is what turns software into infrastructure. The magic word for that is <break strength="weak"/>'open standards'. <break strength="weak"/><prosody volume="x-loud"><voice-transformation type="Custom" rate="fast" strength="100%">OK, that’s actually two words.</voice-transformation></prosody><break strength="weak"/>We are convinced that the future of the humanities and social sciences is in solid data-driven science. Connected software systems are crucial for that. It allows us to combine datasets from entirely different fields. Such as historical sources with archeology, cultural heritage, governments, and corporations. <break strength="weak"/>And it also opens up humanities research for further use by the media, policy makers, journalists, teachers and many others. 

	<break strength="medium"/>Looking at archive and research infrastructure. <break strength="weak"/>These must be clearly separated. <break strength="weak"/>Researchers not just desire to work with our own collections. They need to be able to analyze data from all over the Netherlands, from Europe, and actually from across the globe. Archive infrastructure needs to be sustainable, and expose only carefully curated data. <break strength="weak"/>Research infrastructure on the other hand is volatile. It is dynamic and subject to change. It must be able to handle data that is not cleaned, or carefully selected. <break strength="weak"/><prosody volume="x-loud"><voice-transformation type="Custom" rate="fast" strength="100%">It needs to be open for experimentation</voice-transformation></prosody>
</express-as>
</speak>

<speak>
<express-as type="GoodNews">
	We distinguish three data streams in Research Infrastructure. The first handles the digital representation of reality. It contains: Images, Audio and Video.<break strength="weak"/>Image software, for example, can extract text, detect faces, analyze ink color, or identify typewriters.

	<break strength="medium"/>The second stream continues where the first stops and handles transcribed reality. It works not only with manually transcribed sources but more and more with automatically generated texts. Through optical character recognition, hand-written text analyses, or speech-to-text audio processing.<break strength="weak"/>With a transcription of varying quality available we can start extracting linguistic elements, such as nouns, verbs, and sentence structure, as well as detect names of people, places, objects and dates.

	<break strength="medium"/>Detecting that a combination of letters is a noun, and likely the name of a person, is only half the job. To make sense we need to know who the name actually belongs to. To do that we come to the third and final data stream: structured data. <break strength="weak"/>This is the semantic representation of reality. <break strength="weak"/>Large graphs of identified people, with birth date and location, and many other characteristics. <break strength="weak"/>We add these records to locations, objects, events, that were collected over centuries of research. Combined they form knowledge graphs and explain how people are connected, where they worked, <break strength="weak"/>lived, and traveled. <break strength="medium"/>A process called: disambiguation, identifies the name that was recognized in a transcription. It links the occurrence in a text, to the known person in the knowledge graph, and makes the entire context available to the researcher.

	<break strength="medium"/>Through this process we are capable of working with 17th century shipping records, identify the sailors on board, and follow their careers. We can follow the voyages of individual ships, goods, texts, books, and even ideas, through time and space.

	<break strength="weak"/><prosody volume="x-loud"><voice-transformation type="Custom" rate="fast" strength="100%">Don’t believe us? We’ll show you.</voice-transformation></prosody>
</express-as>
</speak>

<speak>
<express-as type="GoodNews">
	TRIADO is one of those projects in which a lot of technology comes together. The project is funded by the Academy’s research fund and aims to automate access to the archives of the Dutch tribunals prosecuting crimes committed in the country during </express-as>World War Two.<express-as type="GoodNews"> Together with the National Archives and the </express-as><express-as type="Uncertainty">Dutch Institute for War, Holocaust and Genocide Studies</express-as><express-as type="GoodNews"> we are digitizing thirteen meters of dossiers as a pilot sample. The scans are then processed in a pipeline of image tooling that classifies documents and generates text. This transcription is handed over to language software that recognizes </express-as>war criminals, partisans, witnesses, and victims, <express-as type="GoodNews">and connects them to existing databanks.
</express-as>
</speak>

<speak>
<express-as type="GoodNews">
		We want to make every text available to a wide audience such as researchers and students, but also teachers, and the general public. Anything written down is a potential source: <break strength="weak"/>historical documents, literature, primary and secondary sources, written media, and tweets. We have developed several products to do that, and now we are aiming to bring those together. <break strength="x-weak"/>We used to focus on the availability of PDF collections. <break strength="x-weak"/>But the aim in modern tools has shifted away from files. We now provide platforms that combine text and context.  
	
	<break strength="medium"/>In products such as</express-as> Nayderlab and Pergamon Text,<express-as type="GoodNews"> we look at the integration of sources, and the ability to analyze them across time and space. No longer will we decide for you which data<break strength="x-weak"/> you’re interested in. In the old days we only offered a defined collection, like the letters of Descartes, but in these tools you can choose yourself which<break strength="x-weak"/> resources you wish to combine. You can bring together texts from many different authors and institutions across ages. We call these virtual collections.

	<break strength="medium"/>Nayderlab has specific features to support these virtual collections. The platform aids the user in the search through time. For example <break strength="weak"/>through a method we call <break strength="weak"/>lexical query expansion.<break strength="weak"/> When the user enters a search term, the software knows that it needs to search for different words in different periods. The system helps the user in formulating a question by linking modern,</express-as><express-as type="Apology"> early-modern,</express-as><express-as type="GoodNews"> and medieval Dutch dictionaries in a network of words.
</express-as>
</speak>

<speak>
<express-as type="GoodNews">
	We extract information from sources. We link occurrences in texts of people, places, and events, to known data. Such networks are called:<break strength="weak"/> knowledge graphs.<break strength="weak"/> And these also allow people to do research across time and space. In our latest tool <break strength="weak"/>‘Halicarnassus’,<break strength="weak"/> we have developed a </express-as>visual<express-as type="GoodNews"> environment that brings these two dimensions together. Halicarnassus allows the user to come as close as possible to actual</express-as> time travel.<express-as type="GoodNews">

		As an example we have taken the travels of the Dutch seafarer <break strength="x-weak"/>Ahbel Tasman. In the first half of the 17th century he was send out twice in search of the mysterious land known as <break strength="x-weak"/>Terra Australis. From his logs we extracted his location to linked data, and mapped his first trip in time and space.<break strength="weak"/><prosody volume="x-loud"> If there was a medal for not finding Australia, Tasman would probably have won it. When looking at this, we cannot stop thinking, how can you miss this!</prosody> At least he did manage to discover Tasmania, the island that still carries his name. And on his second trip he eventually discovered Australia and explored large sections of the continent’s northern coast.

	<break strength="weak"/>Halicarnassus is more than just a nice moving image of Tasman’s travels. We are currently working hard to make the tool compatible with all the geographical data that is stored in our knowledge graphs. This allows you to visualize movement and follow the migration of people, objects, and ideas, through time and space.
</express-as>
</speak>

<speak>
<express-as type="GoodNews">
	The Royal Netherlands Academy and the Dutch Research Council, NWO, are deeply invested in delivering the best digital laboratories for research in the humanities and social sciences. The unit for digital infrastructure at the Humanities Cluster is the</express-as> epitome<express-as type="GoodNews"> of this investment.<break strength="weak"/> Over 35 engineers and staff are fully dedicated to making sources available for advanced study. These sources have been collected in over a century of research by the three institutes that form the </express-as>cluster.<express-as type="GoodNews"> <break strength="medium"/><prosody volume="x-loud">Now the academy is taking the next step: <break strength="weak"/>away from making the humanities more digital, and towards making the computational sciences more humanist!</prosody>
</express-as>
</speak>
